import traceback
import streamlit as st
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnableLambda
from langchain.text_splitter import RecursiveCharacterTextSplitter
# models
from langchain_openai import ChatOpenAI
import tiktoken

import requests
from bs4 import BeautifulSoup
from typing import cast
from urllib.parse import urlparse


SUMMARIZE_PROMPT:str = """ä»¥ä¸‹ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã«ã¤ã„ã¦ã€å†…å®¹ã‚’300å­—ç¨‹åº¦ã§ã‚ã‹ã‚Šã‚„ã™ãè¦ç´„ã—ã¦ãã ã•ã„
========
{content}
========
æ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ã€‚
"""


def init_page():
    st.set_page_config(
        page_title="Webè¦ç´„ã‚¢ãƒ—ãƒª",
        page_icon="ğŸ“„",
    )
    st.header("Webè¦ç´„ã‚¢ãƒ—ãƒªğŸ“„")
    st.sidebar.title("è¨­å®š")


def select_model(temperature:float=0) -> ChatOpenAI:
    models = ("gpt-4.1-nano", "gpt-4.1-mini", "o4-mini")
    model = st.sidebar.radio("Choose a model:", models)
    if model is None:
        model = "gpt-4.1-nano" # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
    
    if model == "o4-mini":
        st.sidebar.write("ã“ã®ãƒ¢ãƒ‡ãƒ«ã§ã¯ temperature ã¯ 1.0 å›ºå®šã§ã™")
        temperature = 1.0
    else:
        temperature = st.sidebar.slider(
            "Temperature:", min_value=0.0, max_value=2.0, step=0.1 
        )
    
    llm = ChatOpenAI(temperature=temperature, model=model)
    st.session_state.model_name = model  # session_stateã«ä¿å­˜
    st.sidebar.write(f"[DEBUG]â–¶ Using LLM: {model}, temperature={getattr(llm, 'temperature', 'N/A')}")
    return llm


def init_summarize_chain():
    llm = select_model()
    prompt = ChatPromptTemplate.from_messages([
        ("user", SUMMARIZE_PROMPT),
    ])
    output_parser = StrOutputParser()
    chain = prompt | llm | output_parser
    return chain

def init_chain():
    summarize_chain = init_summarize_chain()

    text_splitter = \
        RecursiveCharacterTextSplitter.from_tiktoken_encoder(
            # ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚Šãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚«ã‚¦ãƒ³ãƒˆæ–¹æ³•ãŒé•ã†ãŸã‚ã€model_nameã‚’æŒ‡å®šã™ã‚‹
            model_name = "gpt-4",
            # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã¯ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã§ã‚«ã‚¦ãƒ³ãƒˆ
            chunk_size = 16000,
            chunk_overlap = 0,
            # æ—¥æœ¬èªæ–‡æ›¸ã®å‡¦ç†ã§ã‚»ãƒ‘ãƒ¬ãƒ¼ã‚¿ã‚’å¤‰æ›´ã™ã‚‹ã®ãªã‚‰ä»¥ä¸‹ã®æ–‡ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã‚’å¤–ã™
            # separators=["\n\n", "\n", "ã€‚", "ã€", " ", ""]
            )
    text_split = RunnableLambda(
        lambda x: [
        {"content": doc}
        for doc in text_splitter.split_text(
            cast(dict[str, str], x)["content"]
        )
    ]
    )
    text_concat = RunnableLambda(
        lambda x: {"content": "\n".join(cast(list[str], x))}
    )
    map_reduce_chain = (
        text_split | summarize_chain.map() | text_concat | summarize_chain
    )

    def route(x):
        encoding = tiktoken.encoding_for_model("gpt-4")
        token_count = len(encoding.encode(x['content']))
        if token_count > 16000:
            return map_reduce_chain
        else:
            return summarize_chain
    chain = RunnableLambda(route)
    return chain




def validate_url(url: str) -> bool:
    """URLã®å½¢å¼ã‚’æ¤œè¨¼ã™ã‚‹"""
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False
    

def get_content(url: str) -> str | None:
    """æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ã™ã‚‹"""
    try:
        with st.spinner("Fetching Content... / ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ä¸­..."):
            response = requests.get(url)
            response.raise_for_status()  # HTTPã‚¨ãƒ©ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # ãªã‚‹ã¹ãæœ¬æ–‡ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„è¦ç´ ã‚’æŠ½å‡º
            if soup.main:
                return soup.main.get_text()
            elif soup.article:
                return soup.article.get_text()
            elif soup.body:
                return soup.body.get_text()
            else:
                return soup.get_text()
    except Exception as e:
        st.error(f"Error fetching content: {e}")
        return None


def main():
    init_page()
    chain = init_chain()

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if url := st.text_input("URL: ", key="input"):
        is_valid_url = validate_url(url)
        if not is_valid_url:
            st.error("ç„¡åŠ¹ãªURLã§ã™ã€‚æ­£ã—ã„URLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
        else:
            if content := get_content(url):
                st.markdown("### è¦ç´„")
                st.write_stream(chain.stream({"content": content}))
                st.markdown("---")
                st.markdown("### å…ƒã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„")
                st.text(content)

    # ã‚³ã‚¹ãƒˆã‚’è¡¨ç¤ºã™ã‚‹å ´åˆã¯ç¬¬3ç« ã¨åŒæ§˜ã«å®Ÿè£…
    # calc_and_display_costs()


if __name__ == "__main__":
    main()